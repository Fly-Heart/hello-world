大数据入门之参数配置：

***********************************************************************************************************************

#setup for java --vim /etc/profile
export JAVA_HOME=/opt/module/jdk1.8.0_201
export JRE_HOME=${JAVA_HOME}/jre  
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  
export PATH=${JAVA_HOME}/bin:$PATH


#setup for hadoop --vim /etc/profile
export HADOOP_HOME=/opt/module/hadoop-2.8.0
export PATH=${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH

# vim hadoop-env.sh
# 指定JDK的安装位置
export JAVA_HOME=/opt/module/jdk1.8.0_201


# vim core-site.xml
<configuration>
  <property>
    <!--指定 namenode 的 hdfs 协议文件系统的通信地址-->
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop101:8020</value>
  </property>
  <property>
    <!--指定 hadoop 集群存储临时文件的目录-->
    <name>hadoop.tmp.dir</name>
    <value>/study/hadoop/tmp</value>
  </property>
</configuration>


# vim  hdfs-site.xml
<property>
  <!--namenode 节点数据（即元数据）的存放位置，可以指定多个目录实现容错，多个目录用逗号分隔-->
  <name>dfs.namenode.name.dir</name>
  <value>/study/hadoop/namenode/data</value>
</property>
<property>
  <!--datanode 节点数据（即数据块）的存放位置-->
  <name>dfs.datanode.data.dir</name>
  <value>/study/hadoop/datanode/data</value>
</property>

# vim yarn-site.xml
<configuration>
  <property>
    <!--配置 NodeManager 上运行的附属服务。需要配置成 mapreduce_shuffle 后才可以在Yarn 上运行 MapReduce 程序。-->
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <!--resourcemanager 的主机名-->
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop101</value>
  </property>
</configuration>


# vim mapred-site.xml
<configuration>
    <property>
        <!--指定 mapreduce 作业运行在 yarn 上-->
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>


# vim slaves
hadoop101
hadoop102
hadoop103








**************************************************************************************************************

su -
mkdir study;chmod 777 study
mkdir /study/hadoop/tmp /study/hadoop/namenode/data /study/hadoop/datanode/data

#将 Hadoop 安装包分发到其他两台服务器，分发后建议在这两台服务器上也配置一下 Hadoop 的环境变量。
# 将安装包分发到hadoop102
scp -r /opt/module/hadoop-2.8.0 hadoop102:/opt/module/
# 将安装包分发到hadoop103
scp -r /opt/module/hadoop-2.8.0 hadoop103:/opt/module/






建立集群免密
分发JDK，并安装

scp -r /opt/module/jdk1.8.0_201 richard-@hadoop101:/opt/module